{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec248b8c-fee0-472f-8a7c-e9d65b4be936",
   "metadata": {},
   "source": [
    "# Example 1: Sinatra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e01f255-9398-4a55-af3c-f9a0c6132534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_utils import make_task, transcribe_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1566d81b-d5a5-473c-8683-2dd96924bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/watch?v=ZEcqHA7dbwM'\n",
    "model_type = 'tiny'\n",
    "transcription_task = make_task(url, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d55424-a17f-4eac-aa2d-dce76bec3d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tiny model...\n",
      "Model loaded succssfully...\n",
      "Transcribing ./youtube-flow-audio-files/fly_me_to_the_moon_2008_remastered...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddie/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Let me play among the stars. Let me see what spring is like on. As you put a mask, in other words, hold my hand. In other words, baby kiss me. Fill my heart with song and let me sing forevermore. You are all I long for, all I worship and the dawn. In other words, please be true. In other words, I love you. Fill my heart with song and let me sing forevermore. You are all I long for, all I worship and the dawn. In other words, please be true. In other words, in other words, I love you. You.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription = transcribe_video(transcription_task)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672e55f-163d-4f43-bd2e-c6ed0fcbc934",
   "metadata": {},
   "source": [
    "# Example 2: Fireside Chat #1\n",
    "* Video Time: 02:21:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361a312a-a8c3-4645-80ce-fe02d1294396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tiny model...\n",
      "Model loaded succssfully...\n",
      "Transcribing ./youtube-flow-audio-files/fireside_chat_1_how_to_produce_sustainable_business_value_with_machine_learning...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddie/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "File \u001b[0;32m~/Dev/operationalizing-whisper/youtube_utils.py:67\u001b[0m, in \u001b[0;36mtranscribe_video\u001b[0;34m(transcription_task, output_path)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded succssfully...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(audio_filename))\n\u001b[0;32m---> 67\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/whisper/transcribe.py:181\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, **decode_options)\u001b[0m\n\u001b[1;32m    178\u001b[0m segment_duration \u001b[38;5;241m=\u001b[39m segment\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m HOP_LENGTH \u001b[38;5;241m/\u001b[39m SAMPLE_RATE\n\u001b[1;32m    180\u001b[0m decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 181\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/whisper/transcribe.py:117\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    114\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    116\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[0;32m--> 117\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression_ratio_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decode_result\u001b[38;5;241m.\u001b[39mcompression_ratio \u001b[38;5;241m>\u001b[39m compression_ratio_threshold:\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/whisper/decoding.py:701\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single:\n\u001b[1;32m    699\u001b[0m     mel \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 701\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single:\n\u001b[1;32m    704\u001b[0m     result \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/whisper/decoding.py:617\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    614\u001b[0m tokenizer: Tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\n\u001b[1;32m    615\u001b[0m n_audio: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m mel\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 617\u001b[0m audio_features: Tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_audio_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# encoder forward pass\u001b[39;00m\n\u001b[1;32m    618\u001b[0m tokens: Tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_tokens])\u001b[38;5;241m.\u001b[39mrepeat(n_audio, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    620\u001b[0m \u001b[38;5;66;03m# detect language if requested, overwriting the language token\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/whisper/decoding.py:561\u001b[0m, in \u001b[0;36mDecodingTask._get_audio_features\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    559\u001b[0m     audio_features \u001b[38;5;241m=\u001b[39m mel\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 561\u001b[0m     audio_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m audio_features\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mfloat16 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfloat32):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_features has an incorrect dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_features\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/whisper/model.py:156\u001b[0m, in \u001b[0;36mAudioEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m x \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_embedding)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 156\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_post(x)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/whisper/model.py:127\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[1;32m    126\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)\n\u001b[0;32m--> 127\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/whisper/model.py:36\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "url = 'https://www.youtube.com/watch?v=Dr6DsWa6Dhg'\n",
    "model_type = 'tiny'\n",
    "transcription_task = make_task(url, model_type)\n",
    "fs_chat_transcription = transcribe_video(transcription_task)\n",
    "fs_chat_transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f22bd25-643c-4d84-adbe-ca638db1424d",
   "metadata": {},
   "source": [
    "# Running Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f162e-e53e-474b-858f-69a70a079578",
   "metadata": {},
   "source": [
    "## Transcribe one Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0eb6605e-d14f-4766-af7f-eecbdfa93629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.7.11\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mYouTubeVideoTranscription\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:eddie\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m2022-10-08 18:56:08.964 \u001b[0m\u001b[1mWorkflow starting (run-id 184193):\u001b[0m\n",
      "\u001b[35m2022-10-08 18:56:10.591 \u001b[0m\u001b[32m[184193/start/1001752 (pid 64624)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:56:18.503 \u001b[0m\u001b[32m[184193/start/1001752 (pid 64624)] \u001b[0m\u001b[1mForeach yields 1 child steps.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:56:18.503 \u001b[0m\u001b[32m[184193/start/1001752 (pid 64624)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:56:21.215 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:56:23.142 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Task is starting (Pod is pending, Container is waiting - ContainerCreating)...\u001b[0m\n",
      "\u001b[35m2022-10-08 18:56:53.238 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Task is starting (Pod is pending, Container is waiting - ContainerCreating)...\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:23.913 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Task is starting (Pod is pending, Container is waiting - ContainerCreating)...\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:06.821 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Setting up task environment.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:23.286 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Downloading code package...\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:24.048 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Code package downloaded.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:24.070 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Task is starting.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:25.413 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b]\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:25.413 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Installing Python packages using pip...\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:25.730 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: jiwer in /usr/local/lib/python3.10/site-packages (2.5.1)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:25.733 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: levenshtein==0.20.2 in /usr/local/lib/python3.10/site-packages (from jiwer) (0.20.2)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:25.736 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.10/site-packages (from levenshtein==0.20.2->jiwer) (2.11.1)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:26.565 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Collecting git+https://github.com/openai/whisper.git\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:26.566 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b]   Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-w_fp_ld3\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:27.666 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b]   Resolved https://github.com/openai/whisper.git to commit 9e653bd0ea0f1e9493cb4939733e9de249493cfb\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:27.668 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b]   Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:26.171 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:26.567 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b]   Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-w_fp_ld3\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:27.874 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b]   Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:27.880 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from whisper==1.0) (1.23.3)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:27.880 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: torch in /usr/local/lib/python3.10/site-packages (from whisper==1.0) (1.12.1)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:27.881 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from whisper==1.0) (4.64.1)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:27.881 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/site-packages (from whisper==1.0) (8.14.0)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:27.882 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.10/site-packages (from whisper==1.0) (4.22.2)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:27.883 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/site-packages (from whisper==1.0) (0.2.0)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:27.888 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: future in /usr/local/lib/python3.10/site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.185 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.185 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.186 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (0.10.0)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.187 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.187 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (0.12.1)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.188 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.188 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers>=4.19.0->whisper==1.0) (2022.9.13)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.199 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch->whisper==1.0) (4.4.0)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.233 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.255 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.256 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.12)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.257 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.1.1)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.258 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.4)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.729 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: pytube==12.1.0 in /usr/local/lib/python3.10/site-packages (12.1.0)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:28.352 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:29.154 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:29.554 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/site-packages (0.2.0)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:29.560 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Requirement already satisfied: future in /usr/local/lib/python3.10/site-packages (from ffmpeg-python==0.2.0) (0.18.2)\u001b[0m\n",
      "\u001b[35m2022-10-08 18:57:29.975 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "100%|███████████████████████████████████████| 461M/461M [00:10<00:00, 47.0MiB/s]\u001b[0m22m[pod t-vll8s-k8n7b] \n",
      "\u001b[35m2022-10-08 18:58:45.042 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[22m[pod t-vll8s-k8n7b] Task finished with exit code 0.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:58:46.079 \u001b[0m\u001b[32m[184193/transcribe/1001753 (pid 64634)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:58:47.573 \u001b[0m\u001b[32m[184193/postprocess_transcription/1001754 (pid 64652)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:58:54.863 \u001b[0m\u001b[32m[184193/postprocess_transcription/1001754 (pid 64652)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:58:56.142 \u001b[0m\u001b[32m[184193/end/1001755 (pid 64656)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:59:00.787 \u001b[0m\u001b[32m[184193/end/1001755 (pid 64656)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
      "\u001b[35m2022-10-08 18:59:01.093 \u001b[0m\u001b[1mDone!\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! python youtube_video_transcriber.py run --url 'https://www.youtube.com/watch?v=ZEcqHA7dbwM'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9ceda2-61da-4942-a1bc-3eae82258338",
   "metadata": {},
   "source": [
    "## Transcribe each Video in a Playlist\n",
    "\n",
    "[This url](https://www.youtube.com/playlist?list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc) goes to the playlist for Ville's [tagging blog](/blog/five-ways-to-use-the-new-metaflow-tags/). The playlist consists of 5 videos:\n",
    "* [Basic Tagging](https://www.youtube.com/watch?v=DEmKaTI3MG4&list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc&index=1): 05:41\n",
    "* [Programmatic Tagging](https://www.youtube.com/watch?v=25Hqp43J37I&list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc&index=2): 04:52\n",
    "* [Tags and Namespaces](https://www.youtube.com/watch?v=ifARsmiSNhE&list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc&index=3): 10:34\n",
    "* [Tags in CI/CD](https://www.youtube.com/watch?v=hIiDXPHqEFM&list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc&index=4): 03:28\n",
    "* [Tags and Continuous Training](https://www.youtube.com/watch?v=lZhwhuG0AN8&list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc&index=5): 04:33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec80592d-1606-48ce-b19a-a3c5294ee8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/eddie/Dev/operationalizing-whisper/youtube_video_transcriber.py\", line 11, in <module>\n",
      "    class YouTubeVideoTranscription(FlowSpec):\n",
      "  File \"/Users/eddie/Dev/operationalizing-whisper/youtube_video_transcriber.py\", line 51, in YouTubeVideoTranscription\n",
      "    flag = int(os.getenv('IS_REMOTE'))\n",
      "TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\n"
     ]
    }
   ],
   "source": [
    "! python youtube_video_transcriber.py run \\\n",
    "    --url 'https://www.youtube.com/playlist?list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc' \\\n",
    "    --m 'large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f946db52-0d4b-42ce-b275-a6019453784f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "      <th>model_type</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>views</th>\n",
       "      <th>length (s)</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>publish date</th>\n",
       "      <th>transcribed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://youtube.com/watch?v=hIiDXPHqEFM</td>\n",
       "      <td>metaflow_tags_tags_in_cicd</td>\n",
       "      <td>small</td>\n",
       "      <td>Metaflow Tags: Tags in CI/CD</td>\n",
       "      <td>Outerbounds</td>\n",
       "      <td>45</td>\n",
       "      <td>208</td>\n",
       "      <td>Learn how to use Metaflow tags in conjunction ...</td>\n",
       "      <td>hIiDXPHqEFM</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>Let's turn into more production-oriented use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://youtube.com/watch?v=lZhwhuG0AN8</td>\n",
       "      <td>metaflow_tags_tags_and_continuous_training</td>\n",
       "      <td>small</td>\n",
       "      <td>Metaflow Tags: Tags and Continuous Training</td>\n",
       "      <td>Outerbounds</td>\n",
       "      <td>27</td>\n",
       "      <td>272</td>\n",
       "      <td>Learn how to use tags to facilitate continuous...</td>\n",
       "      <td>lZhwhuG0AN8</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>This last example might be one of the most si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://youtube.com/watch?v=25Hqp43J37I</td>\n",
       "      <td>metaflow_tags_programmatic_tagging</td>\n",
       "      <td>small</td>\n",
       "      <td>Metaflow Tags: Programmatic Tagging</td>\n",
       "      <td>Outerbounds</td>\n",
       "      <td>31</td>\n",
       "      <td>291</td>\n",
       "      <td>Learn how to use Metaflow tags programmaticall...</td>\n",
       "      <td>25Hqp43J37I</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>In some sense this example is an inverse of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://youtube.com/watch?v=ifARsmiSNhE</td>\n",
       "      <td>metaflow_tags_tags_and_namespaces</td>\n",
       "      <td>small</td>\n",
       "      <td>Metaflow Tags: Tags and Namespaces</td>\n",
       "      <td>Outerbounds</td>\n",
       "      <td>17</td>\n",
       "      <td>633</td>\n",
       "      <td>Learn how to use Metaflow tags to create isola...</td>\n",
       "      <td>ifARsmiSNhE</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>From the last two examples, you may have got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://youtube.com/watch?v=DEmKaTI3MG4</td>\n",
       "      <td>metaflow_tags_basic_tagging</td>\n",
       "      <td>small</td>\n",
       "      <td>Metaflow Tags: Basic Tagging</td>\n",
       "      <td>Outerbounds</td>\n",
       "      <td>69</td>\n",
       "      <td>341</td>\n",
       "      <td>Learn how to use Metaflow tags for experiment ...</td>\n",
       "      <td>DEmKaTI3MG4</td>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>Let's start with the very simple use case for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       url  \\\n",
       "0  https://youtube.com/watch?v=hIiDXPHqEFM   \n",
       "1  https://youtube.com/watch?v=lZhwhuG0AN8   \n",
       "2  https://youtube.com/watch?v=25Hqp43J37I   \n",
       "3  https://youtube.com/watch?v=ifARsmiSNhE   \n",
       "4  https://youtube.com/watch?v=DEmKaTI3MG4   \n",
       "\n",
       "                                     filename model_type  \\\n",
       "0                  metaflow_tags_tags_in_cicd      small   \n",
       "1  metaflow_tags_tags_and_continuous_training      small   \n",
       "2          metaflow_tags_programmatic_tagging      small   \n",
       "3           metaflow_tags_tags_and_namespaces      small   \n",
       "4                 metaflow_tags_basic_tagging      small   \n",
       "\n",
       "                                         title       author  views  \\\n",
       "0                 Metaflow Tags: Tags in CI/CD  Outerbounds     45   \n",
       "1  Metaflow Tags: Tags and Continuous Training  Outerbounds     27   \n",
       "2          Metaflow Tags: Programmatic Tagging  Outerbounds     31   \n",
       "3           Metaflow Tags: Tags and Namespaces  Outerbounds     17   \n",
       "4                 Metaflow Tags: Basic Tagging  Outerbounds     69   \n",
       "\n",
       "   length (s)                                        description           id  \\\n",
       "0         208  Learn how to use Metaflow tags in conjunction ...  hIiDXPHqEFM   \n",
       "1         272  Learn how to use tags to facilitate continuous...  lZhwhuG0AN8   \n",
       "2         291  Learn how to use Metaflow tags programmaticall...  25Hqp43J37I   \n",
       "3         633  Learn how to use Metaflow tags to create isola...  ifARsmiSNhE   \n",
       "4         341  Learn how to use Metaflow tags for experiment ...  DEmKaTI3MG4   \n",
       "\n",
       "  publish date                                   transcribed_text  \n",
       "0   2022-06-21   Let's turn into more production-oriented use ...  \n",
       "1   2022-06-21   This last example might be one of the most si...  \n",
       "2   2022-06-21   In some sense this example is an inverse of t...  \n",
       "3   2022-06-21   From the last two examples, you may have got ...  \n",
       "4   2022-06-21   Let's start with the very simple use case for...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = Flow('VideoTranscription').latest_successful_run\n",
    "run.data.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c48f5d4-ff73-48cc-94f1-5f2dc75ec42b",
   "metadata": {},
   "source": [
    "## Transcribe a List of Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344c36b-599c-4bb6-9053-332800391286",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python youtube_video_transcriber.py run --urls 'science_video_urls.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaab3c3-a302-4a31-be63-4f2d4168e9c0",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02265c1c-b405-414f-8818-81f43fb1cef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'17 minutes ago'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import humanize\n",
    "import datetime as dt\n",
    "from metaflow import Flow\n",
    "run = Flow('YouTubeVideoTranscription').latest_successful_run\n",
    "humanize.naturaltime(dt.datetime.now() - run.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04341065-66a5-424f-8599-f4b034a9d4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "      <th>model_type</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>views</th>\n",
       "      <th>length</th>\n",
       "      <th>description</th>\n",
       "      <th>id</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>transcription_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://youtube.com/watch?v=GVsUOuSjvcg</td>\n",
       "      <td>future_computers_will_be_radically_different_a...</td>\n",
       "      <td>tiny</td>\n",
       "      <td>Future Computers Will Be Radically Different (...</td>\n",
       "      <td>Veritasium</td>\n",
       "      <td>8672686</td>\n",
       "      <td>1302</td>\n",
       "      <td>Visit https://brilliant.org/Veritasium/ to get...</td>\n",
       "      <td>GVsUOuSjvcg</td>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>For hundreds of years, analog computers were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://youtube.com/watch?v=ieDIpgso4no</td>\n",
       "      <td>breaking_new_phase_of_matter</td>\n",
       "      <td>tiny</td>\n",
       "      <td>BREAKING: New Phase of Matter</td>\n",
       "      <td>Physics Girl</td>\n",
       "      <td>1445568</td>\n",
       "      <td>934</td>\n",
       "      <td>What are time crystals? How do scientists make...</td>\n",
       "      <td>ieDIpgso4no</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>We're filming a video about time crystals. Ok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://youtube.com/watch?v=Ek1buV2HA68</td>\n",
       "      <td>worlds_only_moving_mud_puddle</td>\n",
       "      <td>tiny</td>\n",
       "      <td>World's Only Moving Mud Puddle</td>\n",
       "      <td>Physics Girl</td>\n",
       "      <td>4100457</td>\n",
       "      <td>699</td>\n",
       "      <td>Want to support more videos like this? Patreon...</td>\n",
       "      <td>Ek1buV2HA68</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>Hey, let's pull them straight in line in here...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://youtube.com/watch?v=ccO0_hSXMyM</td>\n",
       "      <td>how_mirrors_could_solve_our_energy_problem</td>\n",
       "      <td>tiny</td>\n",
       "      <td>How Mirrors Could Solve our Energy Problem</td>\n",
       "      <td>Physics Girl</td>\n",
       "      <td>1072714</td>\n",
       "      <td>690</td>\n",
       "      <td>We visited a giant field of solar mirrors to l...</td>\n",
       "      <td>ccO0_hSXMyM</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>This is 4,000 acres of mirrors. As you drive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://youtube.com/watch?v=S2xHZPH5Sng</td>\n",
       "      <td>clickbait_is_unreasonably_effective</td>\n",
       "      <td>tiny</td>\n",
       "      <td>Clickbait is Unreasonably Effective</td>\n",
       "      <td>Veritasium</td>\n",
       "      <td>6098423</td>\n",
       "      <td>1165</td>\n",
       "      <td>The title and thumbnail play a huge role in a ...</td>\n",
       "      <td>S2xHZPH5Sng</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>Can I tell you something I'm bad at? I am ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://youtube.com/watch?v=HeQX2HjkcNo</td>\n",
       "      <td>maths_fundamental_flaw</td>\n",
       "      <td>tiny</td>\n",
       "      <td>Math's Fundamental Flaw</td>\n",
       "      <td>Veritasium</td>\n",
       "      <td>21846330</td>\n",
       "      <td>2039</td>\n",
       "      <td>Not everything that is true can be proven. Thi...</td>\n",
       "      <td>HeQX2HjkcNo</td>\n",
       "      <td>2021-05-22</td>\n",
       "      <td>There is a hole at the bottom of math. A hole...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       url  \\\n",
       "0  https://youtube.com/watch?v=GVsUOuSjvcg   \n",
       "1  https://youtube.com/watch?v=ieDIpgso4no   \n",
       "2  https://youtube.com/watch?v=Ek1buV2HA68   \n",
       "3  https://youtube.com/watch?v=ccO0_hSXMyM   \n",
       "4  https://youtube.com/watch?v=S2xHZPH5Sng   \n",
       "5  https://youtube.com/watch?v=HeQX2HjkcNo   \n",
       "\n",
       "                                            filename model_type  \\\n",
       "0  future_computers_will_be_radically_different_a...       tiny   \n",
       "1                       breaking_new_phase_of_matter       tiny   \n",
       "2                      worlds_only_moving_mud_puddle       tiny   \n",
       "3         how_mirrors_could_solve_our_energy_problem       tiny   \n",
       "4                clickbait_is_unreasonably_effective       tiny   \n",
       "5                             maths_fundamental_flaw       tiny   \n",
       "\n",
       "                                               title        author     views  \\\n",
       "0  Future Computers Will Be Radically Different (...    Veritasium   8672686   \n",
       "1                      BREAKING: New Phase of Matter  Physics Girl   1445568   \n",
       "2                     World's Only Moving Mud Puddle  Physics Girl   4100457   \n",
       "3         How Mirrors Could Solve our Energy Problem  Physics Girl   1072714   \n",
       "4                Clickbait is Unreasonably Effective    Veritasium   6098423   \n",
       "5                            Math's Fundamental Flaw    Veritasium  21846330   \n",
       "\n",
       "   length                                        description           id  \\\n",
       "0    1302  Visit https://brilliant.org/Veritasium/ to get...  GVsUOuSjvcg   \n",
       "1     934  What are time crystals? How do scientists make...  ieDIpgso4no   \n",
       "2     699  Want to support more videos like this? Patreon...  Ek1buV2HA68   \n",
       "3     690  We visited a giant field of solar mirrors to l...  ccO0_hSXMyM   \n",
       "4    1165  The title and thumbnail play a huge role in a ...  S2xHZPH5Sng   \n",
       "5    2039  Not everything that is true can be proven. Thi...  HeQX2HjkcNo   \n",
       "\n",
       "  publish_date                                 transcription_text  \n",
       "0   2022-03-01   For hundreds of years, analog computers were ...  \n",
       "1   2022-06-15   We're filming a video about time crystals. Ok...  \n",
       "2   2021-05-10   Hey, let's pull them straight in line in here...  \n",
       "3   2021-08-31   This is 4,000 acres of mirrors. As you drive ...  \n",
       "4   2021-08-17   Can I tell you something I'm bad at? I am ter...  \n",
       "5   2021-05-22   There is a hole at the bottom of math. A hole...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.data.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff92f38f-2598-494a-a8f5-f6763948c593",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'transcribed_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribed_text\u001b[49m\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/miniconda3/envs/youtube-transcription/lib/python3.10/site-packages/pandas/core/generic.py:5907\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5901\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5902\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5903\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5904\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5905\u001b[0m ):\n\u001b[1;32m   5906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'transcribed_text'"
     ]
    }
   ],
   "source": [
    "run.data.results.transcribed_text.values[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d2cbd-1bd2-4856-b515-4b6c9122ea56",
   "metadata": {},
   "source": [
    "# Doing Random Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd65022-c99d-4565-9e55-9467b84aac89",
   "metadata": {},
   "source": [
    "## Grab a YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "542363f2-28ab-4bce-9a18-773e5d720a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d9a978c-911d-4ddf-847e-c459b0c95d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = YouTube('https://youtube.com/watch?v=hIiDXPHqEFM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29876557-84d3-4561-9e9a-dcd9db6faa4d",
   "metadata": {},
   "source": [
    "# Notes\n",
    "* `base` model on remote instances produced `RuntimeError: Model has been downloaded but the SHA256 checksum does not not match. Please retry loading the model.` [link](https://github.com/openai/whisper/blob/82725cea9c339cdc3a2004a622bba766b1871945/whisper/__init__.py#L58). Error was on batch cpu compute environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb47b7-a6ff-4e13-a759-79f57d07cafb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
